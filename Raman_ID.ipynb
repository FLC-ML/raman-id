{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Raman ID (Manual Tuning) (Latest)",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FLC-ML/raman-id/blob/master/Raman_ID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgT7Lr9tLZs9",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCSRFo5OLXgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "3e4f31b0-f158-466d-ed82-9730ebb693ef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezh_mXFfKvEd",
        "colab_type": "text"
      },
      "source": [
        "ResNet Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFfKnvZeKTbt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "6c3a05db-4984-4dcc-b7b2-5106f24f6ab9"
      },
      "source": [
        "# import packages\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.layers import BatchNormalization, ZeroPadding1D, Conv1D, AveragePooling1D, MaxPooling1D\n",
        "from tensorflow.keras.layers import Activation, Dense,  Flatten, Input, add, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow import summary\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "# define resnet class\n",
        "class ResNet:\n",
        "  @staticmethod\n",
        "  # build a model out of resblocks\n",
        "  def build(inputShape, resLayers, classes, convLayers, filters, reg=0.0001, bnEps=2e-5, bnMom=0.9, dropout=None, kernel_size=1):\n",
        "    chanDim = -1\n",
        "    inputs = Input(shape=inputShape)\n",
        "\n",
        "    # initial batchnorm and convolutional layer\n",
        "    x = BatchNormalization(axis=chanDim, epsilon = bnEps, momentum=bnMom)(inputs)\n",
        "    x = Conv1D(64, kernel_size=5, strides=1, use_bias=False, padding=\"same\", kernel_regularizer=l2(reg))(inputs)\n",
        "    \n",
        "    x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "       \n",
        "    shortcut = x\n",
        "    \n",
        "\n",
        "    print(\"Resnet Block\")\n",
        "    x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv1D(25, 5, use_bias=False, kernel_regularizer=l2(reg))(x)\n",
        "    print(x.shape)\n",
        "    x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv1D(100, 8, use_bias=False, kernel_regularizer=l2(reg))(x)\n",
        "    print(x.shape)\n",
        "    \n",
        "    shortcut = Conv1D(100, kernel_size=12, use_bias=False, kernel_regularizer=l2(reg))(shortcut)\n",
        "    print(\"*Shortcut shape\", shortcut.shape)\n",
        "\n",
        "    x = add([x, shortcut])\n",
        "\n",
        "    x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = AveragePooling1D(8)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
        "    x = Activation(\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, x, name=\"resnet\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def pretrain(save_directory, features, labels, verbose=1,\n",
        "                                   batch_size=32, \n",
        "                                   epochs=10, \n",
        "                                   filters=(64, 100), \n",
        "                                   resLayers=1, \n",
        "                                   convLayers=1, \n",
        "                                   learningRate=0.01,   \n",
        "                                   dropout=0.8,\n",
        "                                   kernel_size=1):\n",
        "    X = features\n",
        "    y = labels\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01)\n",
        "\n",
        "\n",
        "    # add depth channel\n",
        "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "    # input shape is everything except for the number of samples \n",
        "    # number of classes is the number of unique items in y\n",
        "    in_shape = X_train.shape[1:]\n",
        "    n_classes = len(np.unique(y_train))\n",
        "\n",
        "    # build model\n",
        "    model = ResNet.build(inputShape=in_shape, classes=n_classes, convLayers=convLayers, resLayers=resLayers, filters=filters, dropout=dropout)\n",
        "\n",
        "    # compile, train model\n",
        "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer=Adam(learningRate), metrics = ['accuracy'])\n",
        "    model.summary()\n",
        "    model.fit(X_train, y_train, batch_size=batch_size,epochs=epochs, verbose=verbose)\n",
        "\n",
        "    # test accuracy\n",
        "    accuracy = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
        "    print(\"(pretraining) Testing accuracy from within X_reference.npy and y_reference.npy:\", accuracy[1])\n",
        "\n",
        "    # Save the weights\n",
        "    model.save(save_directory)\n",
        "\n",
        "    # return model\n",
        "    return model\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def finetune(save_directory, features, labels, verbose=1,\n",
        "               learningRate=1e-4,\n",
        "               batch_size=10, \n",
        "               epochs=10):\n",
        "    X = features\n",
        "    y = labels\n",
        "\n",
        "    # create \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
        "\n",
        "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "    \n",
        "    model = load_model(save_directory)\n",
        "  \n",
        "    model.compile(optimizer=Adam(learningRate),  # Very low learning rate\n",
        "    loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
        "    loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
        "    print(\"(finetuning) Testing accuracy from within X_fine and y_fine: \", acc)\n",
        "  \n",
        "    return model"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-5yo5jzK_fx",
        "colab_type": "text"
      },
      "source": [
        "Pretraining Hyperparameters and Testing Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Ndt6ON1Q6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a62ba1aa-3d93-445a-9e30-ae9da083fe2c"
      },
      "source": [
        "# pretrain hyperparameters\n",
        "batch_size = 100\n",
        "epochs = 10\n",
        "verbose = 1\n",
        "filters = (64, 100, 100, 100, 100, 100, 100)\n",
        "resLayers = 1\n",
        "convLayers = 1\n",
        "learningRate = 0.001\n",
        "dropout = 0.8\n",
        "\n",
        "\n",
        "# save_directory is the path where the model will be saved after pretraining \n",
        "# and the path where the finetuning model will read from\n",
        "save_directory = '/content/drive/My Drive/ML Group/Datasets/data/base.h5' \n",
        "\n",
        "\n",
        "# load data (specific to google drive)\n",
        "X_test = np.load('/content/drive/My Drive/ML Group/Datasets/data/X_test.npy')\n",
        "y_test = np.load('/content/drive/My Drive/ML Group/Datasets/data/y_test.npy')\n",
        "\n",
        "X = np.load('/content/drive/My Drive/ML Group/Datasets/data/X_reference.npy')\n",
        "y = np.load('/content/drive/My Drive/ML Group/Datasets/data/y_reference.npy')\n",
        "\n",
        "X_fine = np.load('/content/drive/My Drive/ML Group/Datasets/data/X_finetune.npy')\n",
        "y_fine = np.load('/content/drive/My Drive/ML Group/Datasets/data/y_finetune.npy')\n",
        "\n",
        "print(\"X Reference Dataset Shape: \", X.shape)\n",
        "print(\"y Reference Dataset Shape: \", y.shape)\n",
        "print(\"X Test Dataset Shape: \", X_test.shape)\n",
        "print(\"y Test Dataset Shape: \", y_test.shape)\n",
        "print(\"X Finetuning Dataset Shape: \", X_fine.shape)\n",
        "print(\"y Finetuning Dataset Shape: \", y_fine.shape)\n",
        "\n",
        "indices = np.arange(X.shape[0])\n",
        "indices_t = np.arange(X_test.shape[0])\n",
        "indices_f = np.arange(X_fine.shape[0])\n",
        "\n",
        "np.random.shuffle(indices)\n",
        "np.random.shuffle(indices_t)\n",
        "np.random.shuffle(indices_f)\n",
        "\n",
        "\n",
        "X = X[indices]\n",
        "X_test = X_test[indices_t]\n",
        "X_fine = X_fine[indices_f]\n",
        "y = y[indices]\n",
        "y_test = y_test[indices_t]\n",
        "y_fine = y_fine[indices_f]\n",
        "\n",
        "\n",
        "from time import time\n",
        "t00 = time()\n",
        "\n",
        "pretrained_model = ResNet.pretrain(save_directory=save_directory, features=X, labels=y, verbose=verbose,\n",
        "                                   batch_size=batch_size, \n",
        "                                   epochs=epochs, \n",
        "                                   filters=filters, \n",
        "                                   resLayers=resLayers, \n",
        "                                   convLayers=convLayers, \n",
        "                                   learningRate=learningRate,\n",
        "                                   dropout=dropout)\n",
        "\n",
        "pre_loss, pre_acc = pretrained_model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
        "print(\"Testing loss, accuracy after pretraining from X_test and y_test:\", pre_loss, pre_acc)\n",
        "print('\\n Completed in: {:0.2f}s'.format(time()-t00))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Reference Dataset Shape:  (60000, 1000)\n",
            "y Reference Dataset Shape:  (60000,)\n",
            "X Test Dataset Shape:  (3000, 1000)\n",
            "y Test Dataset Shape:  (3000,)\n",
            "X Finetuning Dataset Shape:  (3000, 1000)\n",
            "y Finetuning Dataset Shape:  (3000,)\n",
            "Resnet Block\n",
            "(None, 996, 25)\n",
            "(None, 989, 100)\n",
            "*Shortcut shape (None, 989, 100)\n",
            "Model: \"resnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 1000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 1000, 64)     320         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 1000, 64)     256         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 1000, 64)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 1000, 64)     256         activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 1000, 64)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 996, 25)      8000        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 996, 25)      100         conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 996, 25)      0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 989, 100)     20000       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 989, 100)     76800       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 989, 100)     0           conv1d_6[0][0]                   \n",
            "                                                                 conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 989, 100)     400         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 989, 100)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_1 (AveragePoo (None, 123, 100)     0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 12300)        0           average_pooling1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 30)           369030      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 30)           0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 475,162\n",
            "Trainable params: 474,656\n",
            "Non-trainable params: 506\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "594/594 [==============================] - 47s 79ms/step - loss: 0.4762 - accuracy: 0.8684\n",
            "Epoch 2/10\n",
            "594/594 [==============================] - 47s 79ms/step - loss: 0.2446 - accuracy: 0.9310\n",
            "Epoch 3/10\n",
            "594/594 [==============================] - 47s 79ms/step - loss: 0.2094 - accuracy: 0.9418\n",
            "Epoch 4/10\n",
            "594/594 [==============================] - 47s 79ms/step - loss: 0.1988 - accuracy: 0.9468\n",
            "Epoch 5/10\n",
            "594/594 [==============================] - 47s 79ms/step - loss: 0.1704 - accuracy: 0.9551\n",
            "Epoch 6/10\n",
            "594/594 [==============================] - 47s 79ms/step - loss: 0.1647 - accuracy: 0.9577\n",
            "Epoch 7/10\n",
            "594/594 [==============================] - 47s 79ms/step - loss: 0.1686 - accuracy: 0.9595\n",
            "Epoch 8/10\n",
            "594/594 [==============================] - 47s 79ms/step - loss: 0.1607 - accuracy: 0.9618\n",
            "Epoch 9/10\n",
            "594/594 [==============================] - 47s 79ms/step - loss: 0.1488 - accuracy: 0.9674\n",
            "Epoch 10/10\n",
            "594/594 [==============================] - 47s 79ms/step - loss: 0.1440 - accuracy: 0.9689\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.2236 - accuracy: 0.9350\n",
            "(pretraining) Testing accuracy from within X_reference.npy and y_reference.npy: 0.9350000023841858\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 5.1597 - accuracy: 0.4800\n",
            "Testing loss, accuracy after pretraining from X_test and y_test: 5.159721374511719 0.47999998927116394\n",
            "\n",
            " Completed in: 473.78s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfWgWY1wK13i",
        "colab_type": "text"
      },
      "source": [
        "Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CruboOEw1SKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4adcd1a5-9b44-41cf-a184-7d1dd4f69501"
      },
      "source": [
        "# finetune hyperparameters\n",
        "ft_batch_size = 30\n",
        "ft_epochs = 10\n",
        "ft_learningRate = 1e-3   \n",
        "\n",
        "from time import time\n",
        "t00 = time()\n",
        "\n",
        "finetuned_model = ResNet.finetune(save_directory=save_directory, features=X_fine, labels=y_fine, epochs=ft_epochs, learningRate=ft_learningRate, batch_size=ft_batch_size)\n",
        "\n",
        "loss, acc = finetuned_model.evaluate(X_test, y_test, batch_size=ft_batch_size, verbose=verbose)\n",
        "print(\"Pretrained accuracy: \", pre_acc)\n",
        "print(\"Fintuned accuracy: \", acc)\n",
        "print('\\n Completed in: {:0.2f}s'.format(time()-t00))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 1000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 1000, 64)     320         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 1000, 64)     256         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 1000, 64)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 1000, 64)     256         activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 1000, 64)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 996, 25)      8000        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 996, 25)      100         conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 996, 25)      0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 989, 100)     20000       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 989, 100)     76800       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 989, 100)     0           conv1d_6[0][0]                   \n",
            "                                                                 conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 989, 100)     400         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 989, 100)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_1 (AveragePoo (None, 123, 100)     0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 12300)        0           average_pooling1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 30)           369030      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 30)           0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 475,162\n",
            "Trainable params: 474,656\n",
            "Non-trainable params: 506\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "95/95 [==============================] - 3s 31ms/step - loss: 1.0562 - accuracy: 0.7582\n",
            "Epoch 2/10\n",
            "95/95 [==============================] - 3s 29ms/step - loss: 0.3132 - accuracy: 0.9165\n",
            "Epoch 3/10\n",
            "95/95 [==============================] - 3s 29ms/step - loss: 0.1682 - accuracy: 0.9681\n",
            "Epoch 4/10\n",
            "95/95 [==============================] - 3s 29ms/step - loss: 0.1031 - accuracy: 0.9930\n",
            "Epoch 5/10\n",
            "95/95 [==============================] - 3s 29ms/step - loss: 0.0741 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "95/95 [==============================] - 3s 30ms/step - loss: 0.0649 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "95/95 [==============================] - 3s 29ms/step - loss: 0.0609 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "95/95 [==============================] - 3s 30ms/step - loss: 0.0572 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "95/95 [==============================] - 3s 30ms/step - loss: 0.0546 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "95/95 [==============================] - 3s 29ms/step - loss: 0.0518 - accuracy: 1.0000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3391 - accuracy: 0.9200\n",
            "(finetuning) Testing accuracy from within X_fine and y_fine:  0.9200000166893005\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.6611 - accuracy: 0.8533\n",
            "Pretrained accuracy:  0.47999998927116394\n",
            "Fintuned accuracy:  0.8533333539962769\n",
            "\n",
            " Completed in: 31.81s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQq7iZr0eQnr",
        "colab_type": "text"
      },
      "source": [
        "Get Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp5ltErx6Nd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = finetuned_model.predict(x = X_test)\n",
        "predIndx = np.argmax(y_pred, axis = 1)\n",
        "print(\"Predictions Shape:\", y_pred.shape)\n",
        "print(\"Classes:\", y_pred[0].shape)\n",
        "print(len(y_pred), \"Predictions Made\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2zsHKE4h9vM",
        "colab_type": "text"
      },
      "source": [
        "Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI4VXlBKiCiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get labels and order\n",
        "\n",
        "ORDER = [16, 17, 14, 18, 15, 20, 21, 24, 23, 26, 27, 28, 29, 25, 6, 7, 5, 3, 4,\n",
        "         9, 10, 2, 8, 11, 22, 19, 12, 13, 0, 1]\n",
        "\n",
        "STRAINS = {}\n",
        "STRAINS[0] = \"C. albicans\"\n",
        "STRAINS[1] = \"C. glabrata\"\n",
        "STRAINS[2] = \"K. aerogenes\"\n",
        "STRAINS[3] = \"E. coli 1\"\n",
        "STRAINS[4] = \"E. coli 2\"\n",
        "STRAINS[5] = \"E. faecium\"\n",
        "STRAINS[6] = \"E. faecalis 1\"\n",
        "STRAINS[7] = \"E. faecalis 2\"\n",
        "STRAINS[8] = \"E. cloacae\"\n",
        "STRAINS[9] = \"K. pneumoniae 1\"\n",
        "STRAINS[10] = \"K. pneumoniae 2\"\n",
        "STRAINS[11] = \"P. mirabilis\"\n",
        "STRAINS[12] = \"P. aeruginosa 1\"\n",
        "STRAINS[13] = \"P. aeruginosa 2\"\n",
        "STRAINS[14] = \"MSSA 1\"\n",
        "STRAINS[15] = \"MSSA 3\"\n",
        "STRAINS[16] = \"MRSA 1 (isogenic)\"\n",
        "STRAINS[17] = \"MRSA 2\"\n",
        "STRAINS[18] = \"MSSA 2\"\n",
        "STRAINS[19] = \"S. enterica\"\n",
        "STRAINS[20] = \"S. epidermidis\"\n",
        "STRAINS[21] = \"S. lugdunensis\"\n",
        "STRAINS[22] = \"S. marcescens\"\n",
        "STRAINS[23] = \"S. pneumoniae 2\"\n",
        "STRAINS[24] = \"S. pneumoniae 1\"\n",
        "STRAINS[25] = \"S. sanguinis\"\n",
        "STRAINS[26] = \"Group A Strep.\"\n",
        "STRAINS[27] = \"Group B Strep.\"\n",
        "STRAINS[28] = \"Group C Strep.\"\n",
        "STRAINS[29] = \"Group G Strep.\"\n",
        "\n",
        "C_albicans = np.where(y==0)\n",
        "C_glabrata = np.where(y==1)\n",
        "K_aerogenes = np.where(y==2)\n",
        "E_coli_1 = np.where(y==3)\n",
        "E_coli_2 = np.where(y==4)\n",
        "E_faecium = np.where(y==5)\n",
        "E_faecalis_1 = np.where(y==6)\n",
        "E_faecalis_2 = np.where(y==7)\n",
        "E_cloacae = np.where(y==8)\n",
        "K_pneumoniae_1 = np.where(y==9)\n",
        "K_pneumoniae_2 = np.where(y==10)\n",
        "P_mirabilis = np.where(y==11)\n",
        "P_aeruginosa_1 = np.where(y==12)\n",
        "P_aeruginosa_2 = np.where(y==13)\n",
        "MSSA_1 = np.where(y==14)\n",
        "MSSA_3 = np.where(y==15)\n",
        "MRSA_1_iso = np.where(y==16)\n",
        "MRSA_2 = np.where(y==17)\n",
        "MSSA_2 = np.where(y==18)\n",
        "S_enterica = np.where(y==19)\n",
        "S_epidermidis = np.where(y==20)\n",
        "S_lugdunensis = np.where(y==21)\n",
        "S_marcescens = np.where(y==22)\n",
        "S_pneumoniae_2 = np.where(y==23)\n",
        "S_pneumoniae_1 = np.where(y==24)\n",
        "S_sanguinis = np.where(y==25)\n",
        "Group_A_Strep = np.where(y==26)\n",
        "Group_B_Strep = np.where(y==27)\n",
        "Group_C_Strep = np.where(y==28)\n",
        "Group_G_Strep = np.where(y==29)\n",
        "\n",
        "label = [STRAINS[i] for i in ORDER]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am1eBH7Rh17i",
        "colab_type": "text"
      },
      "source": [
        "Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSviB8Oih5Fy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "outputId": "c6bb439d-2838-44b6-8705-287c92a91a77"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "import pandas\n",
        "\n",
        "cr = classification_report(y_test, predIndx, target_names = label)\n",
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "MRSA 1 (isogenic)       0.99      0.99      0.99       100\n",
            "           MRSA 2       0.99      1.00      1.00       100\n",
            "           MSSA 1       0.70      0.80      0.74       100\n",
            "           MSSA 2       0.89      1.00      0.94       100\n",
            "           MSSA 3       0.82      0.55      0.66       100\n",
            "   S. epidermidis       0.99      1.00      1.00       100\n",
            "   S. lugdunensis       1.00      0.21      0.35       100\n",
            "  S. pneumoniae 1       0.55      0.87      0.68       100\n",
            "  S. pneumoniae 2       0.74      0.71      0.72       100\n",
            "   Group A Strep.       0.73      0.73      0.73       100\n",
            "   Group B Strep.       0.91      0.92      0.92       100\n",
            "   Group C Strep.       0.58      0.40      0.47       100\n",
            "   Group G Strep.       0.72      0.87      0.79       100\n",
            "     S. sanguinis       1.00      0.71      0.83       100\n",
            "    E. faecalis 1       0.90      1.00      0.95       100\n",
            "    E. faecalis 2       0.77      0.70      0.73       100\n",
            "       E. faecium       0.70      0.85      0.77       100\n",
            "        E. coli 1       0.97      0.61      0.75       100\n",
            "        E. coli 2       0.98      0.93      0.95       100\n",
            "  K. pneumoniae 1       0.97      0.95      0.96       100\n",
            "  K. pneumoniae 2       1.00      1.00      1.00       100\n",
            "     K. aerogenes       0.73      0.95      0.83       100\n",
            "       E. cloacae       0.63      0.82      0.71       100\n",
            "     P. mirabilis       0.87      0.75      0.81       100\n",
            "    S. marcescens       0.70      0.88      0.78       100\n",
            "      S. enterica       0.86      0.89      0.87       100\n",
            "  P. aeruginosa 1       0.94      0.96      0.95       100\n",
            "  P. aeruginosa 2       0.99      1.00      1.00       100\n",
            "      C. albicans       0.93      0.95      0.94       100\n",
            "      C. glabrata       0.89      0.97      0.93       100\n",
            "\n",
            "         accuracy                           0.83      3000\n",
            "        macro avg       0.85      0.83      0.82      3000\n",
            "     weighted avg       0.85      0.83      0.82      3000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoXumxcfMAA8",
        "colab_type": "text"
      },
      "source": [
        "Create Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoKJaIYguCsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot confusion matrix\n",
        "\n",
        "p_test = pretrained_model.predict(X_test).argmax(axis=1)\n",
        "cm = confusion_matrix(y_test, p_test, labels = ORDER)\n",
        "\n",
        "plt.figure(figsize = (15,15))\n",
        "cm = 100*cm / cm.sum(axis = 1)[:,np.newaxis]\n",
        "\n",
        "ax = sns.heatmap(cm, annot = True, cmap = \"YlGnBu\", fmt = '0.0f', \n",
        "                 xticklabels = label, yticklabels = label)\n",
        "#ax.xaxis.tick_top()\n",
        "plt.xticks(rotation = 90)\n",
        "plt.title('Normalized Confusion Matrix', fontsize = 16)\n",
        "plt.xlabel('Predicted', fontsize = 14)\n",
        "plt.ylabel('True', fontsize = 14)\n",
        "plt.savefig('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}