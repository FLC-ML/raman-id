{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Raman ID (Manual Tuning) (Latest)",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FLC-ML/raman-id/blob/master/Raman_ID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgT7Lr9tLZs9",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCSRFo5OLXgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "ddb9b7f9-f2e5-45bc-c446-2df2978957a6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezh_mXFfKvEd",
        "colab_type": "text"
      },
      "source": [
        "ResNet Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFfKnvZeKTbt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "5b6d36fd-fd3f-45ab-901f-f03604220e62"
      },
      "source": [
        "# import packages\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.layers import BatchNormalization, ZeroPadding1D, Conv1D, AveragePooling1D, MaxPooling1D\n",
        "from tensorflow.keras.layers import Activation, Dense,  Flatten, Input, add, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow import summary\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "# define resnet class\n",
        "class ResNet:\n",
        "  @staticmethod\n",
        "  # create one residual block\n",
        "  def residual_module(data, K, convLayers, chanDim=-1, reduce=False, reg=0.0001, bnEps=2e-5, bnMom=0.9, dropout=0.8, kernel_size=1):\n",
        "    K = K*0.25\n",
        "    shortcut = data\n",
        "    x = data\n",
        "\n",
        "    print(\"Resnet Block\")\n",
        "    for i in range(convLayers):\n",
        "      x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "      x = Activation(\"relu\")(x)\n",
        "      \n",
        "      if (i == convLayers - 1):\n",
        "        K = K*4\n",
        "        x = Conv1D(int(K), kernel_size, use_bias=False, kernel_regularizer=l2(reg))(x)\n",
        "      elif (i == int(convLayers/2)):\n",
        "        x = Conv1D(int(K), kernel_size, use_bias=False, kernel_regularizer=l2(reg))(x)\n",
        "      else:\n",
        "        x = Conv1D(int(K), kernel_size, use_bias=False, kernel_regularizer=l2(reg))(x)\n",
        "      if (dropout is not None):\n",
        "        x = Dropout(dropout)(x)\n",
        "     \n",
        "      # print(\"**PostConvolution\", x.shape)\n",
        "      print(\"*ConvGroup\", x.shape, K)\n",
        "\n",
        "    if reduce:\n",
        "      # shortcut = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(shortcut)\n",
        "      shortcut = Conv1D(K, kernel_size, use_bias=False, kernel_regularizer=l2(reg))(shortcut)\n",
        "    print(\"*Shortcut shape\", shortcut.shape)\n",
        "\n",
        "    x = add([x, shortcut])\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  # build a model out of resblocks\n",
        "  def build(inputShape, resLayers, classes, convLayers, filters, reg=0.0001, bnEps=2e-5, bnMom=0.9, dropout=None, kernel_size=1):\n",
        "    chanDim = -1\n",
        "    inputs = Input(shape=inputShape)\n",
        "\n",
        "    # initial batchnorm and convolutional layer\n",
        "    x = BatchNormalization(axis=chanDim, epsilon = bnEps, momentum=bnMom)(inputs)\n",
        "    x = Conv1D(filters[0], 5, strides=2, use_bias=False, padding=\"same\", kernel_regularizer=l2(reg))(inputs)\n",
        "    \n",
        "    x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "       \n",
        "    x = ResNet.residual_module(data=x, K=filters[1], convLayers=convLayers, reduce=True, bnEps=bnEps, bnMom=bnMom)\n",
        "\n",
        "    for i in range(0, resLayers - 1):\n",
        "      x = ResNet.residual_module(data=x, K=filters[1], convLayers=convLayers, bnEps=bnEps, bnMom=bnMom)\n",
        "    \n",
        "    x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = AveragePooling1D(8)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
        "    x = Activation(\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, x, name=\"resnet\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def pretrain(save_directory, features, labels, verbose=1,\n",
        "                                   batch_size=32, \n",
        "                                   epochs=10, \n",
        "                                   filters=(64, 100), \n",
        "                                   resLayers=1, \n",
        "                                   convLayers=1, \n",
        "                                   learningRate=0.01,   \n",
        "                                   dropout=0.8,\n",
        "                                   kernel_size=1):\n",
        "    X = features\n",
        "    y = labels\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01)\n",
        "\n",
        "\n",
        "    # add depth channel\n",
        "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "    # input shape is everything except for the number of samples \n",
        "    # number of classes is the number of unique items in y\n",
        "    in_shape = X_train.shape[1:]\n",
        "    n_classes = len(np.unique(y_train))\n",
        "\n",
        "    # build model\n",
        "    model = ResNet.build(inputShape=in_shape, classes=n_classes, convLayers=convLayers, resLayers=resLayers, filters=filters, dropout=dropout)\n",
        "\n",
        "    # compile, train model\n",
        "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer=Adam(learningRate), metrics = ['accuracy'])\n",
        "\n",
        "    model.fit(X_train, y_train, batch_size=batch_size,epochs=epochs, verbose=verbose)\n",
        "\n",
        "    # test accuracy\n",
        "    accuracy = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
        "    print(\"(pretraining) Testing accuracy from within X_reference.npy and y_reference.npy:\", accuracy[1])\n",
        "\n",
        "    # Save the weights\n",
        "    model.save(save_directory)\n",
        "\n",
        "    # return model\n",
        "    return model\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def finetune(save_directory, features, labels, verbose=1,\n",
        "               learningRate=1e-4,\n",
        "               batch_size=10, \n",
        "               epochs=10):\n",
        "    X = features\n",
        "    y = labels\n",
        "\n",
        "    # create \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
        "\n",
        "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "    \n",
        "    model = load_model(save_directory)\n",
        "  \n",
        "    model.compile(optimizer=Adam(learningRate),  # Very low learning rate\n",
        "    loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
        "    loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
        "    print(\"(finetuning) Testing accuracy from within X_fine and y_fine: \", acc)\n",
        "  \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-5yo5jzK_fx",
        "colab_type": "text"
      },
      "source": [
        "Pretraining Hyperparameters and Testing Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Ndt6ON1Q6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "93f49506-f68d-4a0d-cdbd-7442f83edb85"
      },
      "source": [
        "# pretrain hyperparameters\n",
        "batch_size = 100\n",
        "epochs = 10\n",
        "verbose = 1\n",
        "filters = (64, 100, 100, 100, 100, 100, 100)\n",
        "resLayers = 6\n",
        "convLayers = 4\n",
        "learningRate = 0.001\n",
        "dropout = 0.8\n",
        "kernel_size = 1\n",
        "\n",
        "\n",
        "# save_directory is the path where the model will be saved after pretraining \n",
        "# and the path where the finetuning model will read from\n",
        "save_directory = '/content/drive/My Drive/ML Group/Individual Work/Kaitlyn/Saved Models/base.h5' \n",
        "\n",
        "\n",
        "# load data (specific to google drive)\n",
        "X_test = np.load('/content/drive/My Drive/ML Group/Datasets/data/X_test.npy')\n",
        "y_test = np.load('/content/drive/My Drive/ML Group/Datasets/data/y_test.npy')\n",
        "\n",
        "X = np.load('/content/drive/My Drive/ML Group/Datasets/data/X_reference.npy')\n",
        "y = np.load('/content/drive/My Drive/ML Group/Datasets/data/y_reference.npy')\n",
        "\n",
        "X_fine = np.load('/content/drive/My Drive/ML Group/Datasets/data/X_finetune.npy')\n",
        "y_fine = np.load('/content/drive/My Drive/ML Group/Datasets/data/y_finetune.npy')\n",
        "\n",
        "print(\"X Reference Dataset Shape: \", X.shape)\n",
        "print(\"y Reference Dataset Shape: \", y.shape)\n",
        "print(\"X Test Dataset Shape: \", X_test.shape)\n",
        "print(\"y Test Dataset Shape: \", y_test.shape)\n",
        "print(\"X Finetuning Dataset Shape: \", X_fine.shape)\n",
        "print(\"y Finetuning Dataset Shape: \", y_fine.shape)\n",
        "\n",
        "indices = np.arange(X.shape[0])\n",
        "indices_t = np.arange(X_test.shape[0])\n",
        "indices_f = np.arange(X_fine.shape[0])\n",
        "\n",
        "np.random.shuffle(indices)\n",
        "np.random.shuffle(indices_t)\n",
        "np.random.shuffle(indices_f)\n",
        "\n",
        "\n",
        "X = X[indices]\n",
        "X_test = X_test[indices_t]\n",
        "X_fine = X_fine[indices_f]\n",
        "y = y[indices]\n",
        "y_test = y_test[indices_t]\n",
        "y_fine = y_fine[indices_f]\n",
        "\n",
        "\n",
        "from time import time\n",
        "t00 = time()\n",
        "\n",
        "pretrained_model = ResNet.pretrain(save_directory=save_directory, features=X, labels=y, verbose=verbose,\n",
        "                                   batch_size=batch_size, \n",
        "                                   epochs=epochs, \n",
        "                                   filters=filters, \n",
        "                                   resLayers=resLayers, \n",
        "                                   convLayers=convLayers, \n",
        "                                   learningRate=learningRate,\n",
        "                                   dropout=dropout,\n",
        "                                   kernel_size=kernel_size)\n",
        "\n",
        "pre_loss, pre_acc = pretrained_model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
        "print(\"Testing loss, accuracy after pretraining from X_test and y_test:\", pre_loss, pre_acc)\n",
        "print('\\n Completed in: {:0.2f}s'.format(time()-t00))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Reference Dataset Shape:  (60000, 1000)\n",
            "y Reference Dataset Shape:  (60000,)\n",
            "X Test Dataset Shape:  (3000, 1000)\n",
            "y Test Dataset Shape:  (3000,)\n",
            "X Finetuning Dataset Shape:  (3000, 1000)\n",
            "y Finetuning Dataset Shape:  (3000,)\n",
            "Resnet Block\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 100) 100.0\n",
            "*Shortcut shape (None, 500, 100)\n",
            "Resnet Block\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 100) 100.0\n",
            "*Shortcut shape (None, 500, 100)\n",
            "Resnet Block\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 100) 100.0\n",
            "*Shortcut shape (None, 500, 100)\n",
            "Resnet Block\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 100) 100.0\n",
            "*Shortcut shape (None, 500, 100)\n",
            "Resnet Block\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 100) 100.0\n",
            "*Shortcut shape (None, 500, 100)\n",
            "Resnet Block\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 25) 25.0\n",
            "*ConvGroup (None, 500, 100) 100.0\n",
            "*Shortcut shape (None, 500, 100)\n",
            "Epoch 1/10\n",
            " 8/30 [=======>......................] - ETA: 38s - loss: 3.6588 - accuracy: 0.0413"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-4-3e152edfa3f6>\", line 63, in <module>\n",
            "    kernel_size=kernel_size)\n",
            "  File \"<ipython-input-3-fc8452e97ff0>\", line 118, in pretrain\n",
            "    model.fit(X_train, y_train, batch_size=batch_size,epochs=epochs, verbose=verbose)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 66, in _method_wrapper\n",
            "    return method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 848, in fit\n",
            "    tmp_logs = train_function(iterator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 611, in _call\n",
            "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2420, in __call__\n",
            "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1665, in _filtered_call\n",
            "    self.captured_inputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1746, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 598, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
            "    if not islink(newpath):\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 171, in islink\n",
            "    st = os.lstat(path)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfWgWY1wK13i",
        "colab_type": "text"
      },
      "source": [
        "Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CruboOEw1SKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00894842-e816-4b43-ff67-957975907463"
      },
      "source": [
        "# finetune hyperparameters\n",
        "ft_batch_size = 10\n",
        "ft_epochs = 8\n",
        "ft_learningRate = 1e-4   \n",
        "\n",
        "from time import time\n",
        "t00 = time()\n",
        "\n",
        "finetuned_model = ResNet.finetune(save_directory=save_directory, features=X_fine, labels=y_fine, epochs=ft_epochs, learningRate=ft_learningRate, batch_size=ft_batch_size)\n",
        "\n",
        "loss, acc = finetuned_model.evaluate(X_test, y_test, batch_size=ft_batch_size, verbose=verbose)\n",
        "print(\"Pretrained accuracy: \", pre_acc)\n",
        "print(\"Fintuned accuracy: \", acc)\n",
        "print('\\n Completed in: {:0.2f}s'.format(time()-t00))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 1000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_21 (Conv1D)              (None, 500, 64)      320         input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 500, 64)      256         conv1d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 500, 64)      0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 500, 64)      256         activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 500, 64)      0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_22 (Conv1D)              (None, 500, 100)     6400        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 500, 100)     0           conv1d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_23 (Conv1D)              (None, 500, 100)     6400        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 500, 100)     0           dropout_7[0][0]                  \n",
            "                                                                 conv1d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 500, 100)     400         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 500, 100)     0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_7 (AveragePoo (None, 62, 100)      0           activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 6200)         0           average_pooling1d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 30)           186030      flatten_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 30)           0           dense_7[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 200,062\n",
            "Trainable params: 199,606\n",
            "Non-trainable params: 456\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/8\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 1.7200 - accuracy: 0.6572\n",
            "Epoch 2/8\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 0.8492 - accuracy: 0.7575\n",
            "Epoch 3/8\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.6646 - accuracy: 0.8063\n",
            "Epoch 4/8\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 0.5569 - accuracy: 0.8333\n",
            "Epoch 5/8\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 0.4779 - accuracy: 0.8565\n",
            "Epoch 6/8\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 0.4213 - accuracy: 0.8765\n",
            "Epoch 7/8\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 0.3685 - accuracy: 0.8968\n",
            "Epoch 8/8\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 0.3333 - accuracy: 0.9077\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8867\n",
            "(finetuning) Testing accuracy from within X_fine and y_fine:  0.8866666555404663\n",
            "300/300 [==============================] - 1s 2ms/step - loss: 0.5957 - accuracy: 0.8337\n",
            "Pretrained accuracy:  0.5026666522026062\n",
            "Fintuned accuracy:  0.8336666822433472\n",
            "\n",
            " Completed in: 9.82s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQq7iZr0eQnr",
        "colab_type": "text"
      },
      "source": [
        "Get Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp5ltErx6Nd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = finetuned_model.predict(x = X_test)\n",
        "predIndx = np.argmax(y_pred, axis = 1)\n",
        "print(\"Predictions Shape:\", y_pred.shape)\n",
        "print(\"Classes:\", y_pred[0].shape)\n",
        "print(len(y_pred), \"Predictions Made\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2zsHKE4h9vM",
        "colab_type": "text"
      },
      "source": [
        "Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI4VXlBKiCiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get labels and order\n",
        "\n",
        "ORDER = [16, 17, 14, 18, 15, 20, 21, 24, 23, 26, 27, 28, 29, 25, 6, 7, 5, 3, 4,\n",
        "         9, 10, 2, 8, 11, 22, 19, 12, 13, 0, 1]\n",
        "\n",
        "STRAINS = {}\n",
        "STRAINS[0] = \"C. albicans\"\n",
        "STRAINS[1] = \"C. glabrata\"\n",
        "STRAINS[2] = \"K. aerogenes\"\n",
        "STRAINS[3] = \"E. coli 1\"\n",
        "STRAINS[4] = \"E. coli 2\"\n",
        "STRAINS[5] = \"E. faecium\"\n",
        "STRAINS[6] = \"E. faecalis 1\"\n",
        "STRAINS[7] = \"E. faecalis 2\"\n",
        "STRAINS[8] = \"E. cloacae\"\n",
        "STRAINS[9] = \"K. pneumoniae 1\"\n",
        "STRAINS[10] = \"K. pneumoniae 2\"\n",
        "STRAINS[11] = \"P. mirabilis\"\n",
        "STRAINS[12] = \"P. aeruginosa 1\"\n",
        "STRAINS[13] = \"P. aeruginosa 2\"\n",
        "STRAINS[14] = \"MSSA 1\"\n",
        "STRAINS[15] = \"MSSA 3\"\n",
        "STRAINS[16] = \"MRSA 1 (isogenic)\"\n",
        "STRAINS[17] = \"MRSA 2\"\n",
        "STRAINS[18] = \"MSSA 2\"\n",
        "STRAINS[19] = \"S. enterica\"\n",
        "STRAINS[20] = \"S. epidermidis\"\n",
        "STRAINS[21] = \"S. lugdunensis\"\n",
        "STRAINS[22] = \"S. marcescens\"\n",
        "STRAINS[23] = \"S. pneumoniae 2\"\n",
        "STRAINS[24] = \"S. pneumoniae 1\"\n",
        "STRAINS[25] = \"S. sanguinis\"\n",
        "STRAINS[26] = \"Group A Strep.\"\n",
        "STRAINS[27] = \"Group B Strep.\"\n",
        "STRAINS[28] = \"Group C Strep.\"\n",
        "STRAINS[29] = \"Group G Strep.\"\n",
        "\n",
        "C_albicans = np.where(y==0)\n",
        "C_glabrata = np.where(y==1)\n",
        "K_aerogenes = np.where(y==2)\n",
        "E_coli_1 = np.where(y==3)\n",
        "E_coli_2 = np.where(y==4)\n",
        "E_faecium = np.where(y==5)\n",
        "E_faecalis_1 = np.where(y==6)\n",
        "E_faecalis_2 = np.where(y==7)\n",
        "E_cloacae = np.where(y==8)\n",
        "K_pneumoniae_1 = np.where(y==9)\n",
        "K_pneumoniae_2 = np.where(y==10)\n",
        "P_mirabilis = np.where(y==11)\n",
        "P_aeruginosa_1 = np.where(y==12)\n",
        "P_aeruginosa_2 = np.where(y==13)\n",
        "MSSA_1 = np.where(y==14)\n",
        "MSSA_3 = np.where(y==15)\n",
        "MRSA_1_iso = np.where(y==16)\n",
        "MRSA_2 = np.where(y==17)\n",
        "MSSA_2 = np.where(y==18)\n",
        "S_enterica = np.where(y==19)\n",
        "S_epidermidis = np.where(y==20)\n",
        "S_lugdunensis = np.where(y==21)\n",
        "S_marcescens = np.where(y==22)\n",
        "S_pneumoniae_2 = np.where(y==23)\n",
        "S_pneumoniae_1 = np.where(y==24)\n",
        "S_sanguinis = np.where(y==25)\n",
        "Group_A_Strep = np.where(y==26)\n",
        "Group_B_Strep = np.where(y==27)\n",
        "Group_C_Strep = np.where(y==28)\n",
        "Group_G_Strep = np.where(y==29)\n",
        "\n",
        "label = [STRAINS[i] for i in ORDER]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am1eBH7Rh17i",
        "colab_type": "text"
      },
      "source": [
        "Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSviB8Oih5Fy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "outputId": "c6bb439d-2838-44b6-8705-287c92a91a77"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "import pandas\n",
        "\n",
        "cr = classification_report(y_test, predIndx, target_names = label)\n",
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "MRSA 1 (isogenic)       0.99      0.99      0.99       100\n",
            "           MRSA 2       0.99      1.00      1.00       100\n",
            "           MSSA 1       0.70      0.80      0.74       100\n",
            "           MSSA 2       0.89      1.00      0.94       100\n",
            "           MSSA 3       0.82      0.55      0.66       100\n",
            "   S. epidermidis       0.99      1.00      1.00       100\n",
            "   S. lugdunensis       1.00      0.21      0.35       100\n",
            "  S. pneumoniae 1       0.55      0.87      0.68       100\n",
            "  S. pneumoniae 2       0.74      0.71      0.72       100\n",
            "   Group A Strep.       0.73      0.73      0.73       100\n",
            "   Group B Strep.       0.91      0.92      0.92       100\n",
            "   Group C Strep.       0.58      0.40      0.47       100\n",
            "   Group G Strep.       0.72      0.87      0.79       100\n",
            "     S. sanguinis       1.00      0.71      0.83       100\n",
            "    E. faecalis 1       0.90      1.00      0.95       100\n",
            "    E. faecalis 2       0.77      0.70      0.73       100\n",
            "       E. faecium       0.70      0.85      0.77       100\n",
            "        E. coli 1       0.97      0.61      0.75       100\n",
            "        E. coli 2       0.98      0.93      0.95       100\n",
            "  K. pneumoniae 1       0.97      0.95      0.96       100\n",
            "  K. pneumoniae 2       1.00      1.00      1.00       100\n",
            "     K. aerogenes       0.73      0.95      0.83       100\n",
            "       E. cloacae       0.63      0.82      0.71       100\n",
            "     P. mirabilis       0.87      0.75      0.81       100\n",
            "    S. marcescens       0.70      0.88      0.78       100\n",
            "      S. enterica       0.86      0.89      0.87       100\n",
            "  P. aeruginosa 1       0.94      0.96      0.95       100\n",
            "  P. aeruginosa 2       0.99      1.00      1.00       100\n",
            "      C. albicans       0.93      0.95      0.94       100\n",
            "      C. glabrata       0.89      0.97      0.93       100\n",
            "\n",
            "         accuracy                           0.83      3000\n",
            "        macro avg       0.85      0.83      0.82      3000\n",
            "     weighted avg       0.85      0.83      0.82      3000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoXumxcfMAA8",
        "colab_type": "text"
      },
      "source": [
        "Create Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoKJaIYguCsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot confusion matrix\n",
        "\n",
        "p_test = pretrained_model.predict(X_test).argmax(axis=1)\n",
        "cm = confusion_matrix(y_test, p_test, labels = ORDER)\n",
        "\n",
        "plt.figure(figsize = (15,15))\n",
        "cm = 100*cm / cm.sum(axis = 1)[:,np.newaxis]\n",
        "\n",
        "ax = sns.heatmap(cm, annot = True, cmap = \"YlGnBu\", fmt = '0.0f', \n",
        "                 xticklabels = label, yticklabels = label)\n",
        "#ax.xaxis.tick_top()\n",
        "plt.xticks(rotation = 90)\n",
        "plt.title('Normalized Confusion Matrix', fontsize = 16)\n",
        "plt.xlabel('Predicted', fontsize = 14)\n",
        "plt.ylabel('True', fontsize = 14)\n",
        "plt.savefig('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}