{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bacteria ResNet",
      "provenance": [],
      "mount_file_id": "1fHeKuEQA1lBIoWFf8RSBpzF1Hq0Xs7OG",
      "authorship_tag": "ABX9TyOmbMY5y3qaXXc3Uwt7vlYr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVmE_TB9TPnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import packages\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2D, AveragePooling2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import Conv1D, AveragePooling1D, MaxPooling1D, ZeroPadding1D\n",
        "from tensorflow.keras.layers import Activation, Dense,  Flatten, Input, add\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "#define resnet class\n",
        "class ResNet:\n",
        "  @staticmethod\n",
        "  #create one residual block\n",
        "  def residual_module(data, K, stride, chanDim, red=False, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
        "    shortcut = data\n",
        "    \n",
        "    bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(data)\n",
        "    act1 = Activation(\"relu\")(bn1)\n",
        "    conv1 = Conv1D(int(K*0.25), 1, use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
        "\n",
        "    bn2 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv1)\n",
        "    act2 = Activation(\"relu\")(bn2)\n",
        "    conv2 = Conv1D(int(K * 0.25), 1, strides=stride, use_bias=False, kernel_regularizer=l2(reg))(act2)\n",
        "    \n",
        "    bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv2)\n",
        "    act3 = Activation(\"relu\")(bn3)\n",
        "    conv3 = Conv1D(K, 1, use_bias=False, kernel_regularizer=l2(reg))(act3)\n",
        "\n",
        "    print(bn2.shape, act2.shape, conv2.shape, bn3.shape)\n",
        "    print(shortcut.shape)\n",
        "\n",
        "    if red:\n",
        "      shortcut = Conv1D(K, 1, strides=stride, use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
        "\n",
        "    x = add([conv3, shortcut])\n",
        "\n",
        "    return x\n",
        "\n",
        "  @staticmethod\n",
        "  #build a model out of resblocks\n",
        "  def build(inputShape, classes, stages, filters, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
        "    chanDim = -1\n",
        "    \n",
        "    inputs = Input(shape=inputShape)\n",
        "    x = BatchNormalization(axis=chanDim, epsilon = bnEps, momentum=bnMom)(inputs)\n",
        "\n",
        "    for i in range(0, len(stages)):\n",
        "      if i == 0:\n",
        "        stride = 1\n",
        "      else:\n",
        "        stride = 2\n",
        "      \n",
        "      x = ResNet.residual_module(x, filters[i + 1], stride, chanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n",
        "\n",
        "      for j in range(0, stages[i] - 1):\n",
        "        x = ResNet.residual_module(x, filters[i + 1], 1, chanDim, bnEps=bnEps, bnMom=bnMom)\n",
        "      \n",
        "      x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "      x = Activation(\"relu\")(x)\n",
        "      x = AveragePooling1D(8)(x)\n",
        "\n",
        "      x = Flatten()(x)\n",
        "      x = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
        "      x = Activation(\"softmax\")(x)\n",
        "\n",
        "      model = Model(inputs, x, name=\"resnet\")\n",
        "\n",
        "      return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKNWE08IICOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#some hyperparameters\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "verbose = 2\n",
        "\n",
        "#load data (specific to google drive)\n",
        "x_train = np.load('/content/drive/My Drive/ML Group/Datasets/data/X_reference.npy')\n",
        "y_train = np.load('/content/drive/My Drive/ML Group/Datasets/data/y_reference.npy')\n",
        "x_test = np.load('/content/drive/My Drive/ML Group/Datasets/data/X_test.npy')\n",
        "y_test = np.load('/content/drive/My Drive/ML Group/Datasets/data/y_test.npy')\n",
        "\n",
        "#add depth channel\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "#input shape is everything except for the number of samples \n",
        "#number of classes is the number of unique items in y\n",
        "in_shape = x_train.shape[1:]\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "#for debugging\n",
        "print(x_train.shape, in_shape)\n",
        "\n",
        "#build model\n",
        "model = ResNet.build(inputShape=in_shape, classes=n_classes, stages=(3, 4, 6), filters=(64, 128, 256, 512))\n",
        "\n",
        "#compile, summarize, train model\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.summary()\n",
        "model.fit(x_train, y_train, batch_size=batch_size,epochs=epochs, verbose=verbose)\n",
        "\n",
        "#test accuracy\n",
        "accuracy = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=verbose)\n",
        "print(accuracy)\n",
        "\n",
        "#delete model\n",
        "del model\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}