{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Raman ID Nic 1 Epoch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VDWWCE527Zb",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZmkjtMf0dWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b991369-81a4-4766-cd26-499b323c17f5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hIPznUM03Dpv"
      },
      "source": [
        "Imports/ResNet Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0orAvBP21_Lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import packages\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import BatchNormalization, ZeroPadding1D, Conv1D, AveragePooling1D, MaxPooling1D\n",
        "from tensorflow.keras.layers import Activation, Dense,  Flatten, Input, add, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow import summary\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "#define resnet class\n",
        "class ResNet:\n",
        "  @staticmethod\n",
        "  #create one residual block\n",
        "  def residual_module(data, K, convLayers, chanDim=-1, reduce=False, reg=0.0001, bnEps=2e-5, bnMom=0.9, dropout=0.8, kernel_size=1):\n",
        "    K = K*0.25\n",
        "    shortcut = data\n",
        "    x = data\n",
        "\n",
        "    print(\"Resnet Block\")\n",
        "    for i in range(convLayers):\n",
        "      x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "      x = Activation(\"relu\")(x)\n",
        "      \n",
        "      if (i == convLayers - 1):\n",
        "        K = K*4\n",
        "        x = Conv1D(int(K), kernel_size, use_bias=False, kernel_regularizer=l2(reg))(x)\n",
        "      elif (i == int(convLayers/2)):\n",
        "        x = Conv1D(int(K), kernel_size, use_bias=False, kernel_regularizer=l2(reg))(x)\n",
        "      else:\n",
        "        x = Conv1D(int(K), kernel_size, use_bias=False, kernel_regularizer=l2(reg))(x)\n",
        "      if (dropout is not None):\n",
        "        x = Dropout(dropout)(x)\n",
        "     \n",
        "      #print(\"**PostConvolution\", x.shape)\n",
        "      print(\"*ConvGroup\", x.shape, K)\n",
        "\n",
        "    if reduce:\n",
        "      #shortcut = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(shortcut)\n",
        "      shortcut = Conv1D(K, kernel_size, use_bias=False, kernel_regularizer=l2(reg))(shortcut)\n",
        "    print(\"*Shortcut shape\", shortcut.shape)\n",
        "\n",
        "    x = add([x, shortcut])\n",
        "\n",
        "    return x\n",
        "\n",
        "  @staticmethod\n",
        "  #build a model out of resblocks\n",
        "  def build(inputShape, resLayers, classes, convLayers, filters, reg=0.0001, bnEps=2e-5, bnMom=0.9, dropout=None, kernel_size=1):\n",
        "    chanDim = -1\n",
        "    inputs = Input(shape=inputShape)\n",
        "\n",
        "    #initial batchnorm and convolutional layer\n",
        "    x = BatchNormalization(axis=chanDim, epsilon = bnEps, momentum=bnMom)(inputs)\n",
        "    x = Conv1D(filters[0], 5, strides=2, use_bias=False, padding=\"same\", kernel_regularizer=l2(reg))(inputs)\n",
        "    \n",
        "    x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "       \n",
        "    x = ResNet.residual_module(data=x, K=filters[1], convLayers=convLayers, reduce=True, bnEps=bnEps, bnMom=bnMom)\n",
        "\n",
        "    for i in range(0, resLayers - 1):\n",
        "      x = ResNet.residual_module(data=x, K=filters[1], convLayers=convLayers, bnEps=bnEps, bnMom=bnMom)\n",
        "    \n",
        "    x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = AveragePooling1D(8)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
        "    x = Activation(\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, x, name=\"resnet\")\n",
        "\n",
        "    return model\n",
        "\n",
        "  @staticmethod\n",
        "  def pretrain(save_directory, features, labels, verbose=1,\n",
        "                                   batch_size=32, \n",
        "                                   epochs=10, \n",
        "                                   filters=(64, 100), \n",
        "                                   resLayers=1, \n",
        "                                   convLayers=1, \n",
        "                                   learningRate=0.1,\n",
        "                                   dropout=0.8,\n",
        "                                   kernel_size=1):\n",
        "    X = features\n",
        "    y = labels\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01)\n",
        "\n",
        "\n",
        "    #add depth channel\n",
        "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "    #input shape is everything except for the number of samples \n",
        "    #number of classes is the number of unique items in y\n",
        "    in_shape = X_train.shape[1:]\n",
        "    n_classes = len(np.unique(y_train))\n",
        "\n",
        "    #build model\n",
        "    model = ResNet.build(inputShape=in_shape, classes=n_classes, convLayers=convLayers, resLayers=resLayers, filters=filters, dropout=dropout)\n",
        "\n",
        "    #compile, train model\n",
        "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer=Adam(learningRate), metrics = ['accuracy'])\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    model.fit(X_train, y_train, batch_size=batch_size,epochs=epochs, verbose=verbose)\n",
        "\n",
        "    #test accuracy\n",
        "    accuracy = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
        "    print(\"(pretraining) Testing accuracy from within X_reference.npy and y_reference.npy:\", accuracy[1])\n",
        "\n",
        "    # Save the weights\n",
        "    model.save(save_directory)\n",
        "\n",
        "    #return model\n",
        "    return model\n",
        "\n",
        "  @staticmethod\n",
        "  def finetune(save_directory, features, labels, verbose=1,\n",
        "               learningRate=1e-5, \n",
        "               batch_size=10, \n",
        "               epochs=10):\n",
        "    X = features\n",
        "    y = labels\n",
        "\n",
        "    #create \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
        "\n",
        "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "    \n",
        "    \n",
        "    model = load_model(save_directory)\n",
        "  \n",
        "    model.compile(optimizer=Adam(learningRate),  # Very low learning rate\n",
        "    loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
        "    loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
        "    print(\"(finetuning) Testing accuracy from within X_fine and y_fine: \", acc)\n",
        "  \n",
        "    return model"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhWAAMZ-3MA5",
        "colab_type": "text"
      },
      "source": [
        "Pretraining Hyperparameters and Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Ndt6ON1Q6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "141d9501-509f-4593-9783-e5ec4f448de8"
      },
      "source": [
        "#pretrain hyperparameters\n",
        "batch_size = 100\n",
        "epochs = 1\n",
        "verbose = 1\n",
        "# filters = (64, 100)\n",
        "filters = (64, 100)\n",
        "resLayers = 1\n",
        "convLayers = 1\n",
        "learningRate = 0.001\n",
        "dropout = 0.8\n",
        "kernel_size = 1\n",
        "\n",
        "\n",
        "#save_directory is the path where the model will be saved after pretraining \n",
        "#and the path where the finetuning model will read from\n",
        "save_directory = '/content/drive/My Drive/Machine_Learning/Saved Models/base.h5' \n",
        "\n",
        "\n",
        "#load data (specific to google drive)\n",
        "X_test = np.load('/content/drive/My Drive/Machine_Learning/Data/X_test.npy')\n",
        "y_test = np.load('/content/drive/My Drive/Machine_Learning/Data/y_test.npy')\n",
        "\n",
        "X = np.load('/content/drive/My Drive/Machine_Learning/Data/X_reference.npy')\n",
        "y = np.load('/content/drive/My Drive/Machine_Learning/Data/y_reference.npy')\n",
        "\n",
        "X_fine = np.load('/content/drive/My Drive/Machine_Learning/Data/X_finetune.npy')\n",
        "y_fine = np.load('/content/drive/My Drive/Machine_Learning/Data/y_finetune.npy')\n",
        "\n",
        "indices = np.arange(X.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "X = X[indices]\n",
        "y = y[indices]\n",
        "\n",
        "pretrained_model = ResNet.pretrain(save_directory=save_directory, features=X, labels=y, verbose=verbose, batch_size=batch_size, epochs=epochs, filters=filters, resLayers=resLayers, convLayers=convLayers, learningRate=learningRate, dropout=dropout, kernel_size=kernel_size)\n",
        "\n",
        "pre_loss, pre_acc = pretrained_model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
        "print(\"Testing loss, accuracy after pretraining from X_test and y_test:\", pre_loss, pre_acc)\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resnet Block\n",
            "*ConvGroup (None, 500, 100) 100.0\n",
            "*Shortcut shape (None, 500, 100)\n",
            "Model: \"resnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_38 (InputLayer)           [(None, 1000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_115 (Conv1D)             (None, 500, 64)      320         input_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 500, 64)      256         conv1d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 500, 64)      0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 500, 64)      256         activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 500, 64)      0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_116 (Conv1D)             (None, 500, 100)     6400        activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 500, 100)     0           conv1d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_117 (Conv1D)             (None, 500, 100)     6400        activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 500, 100)     0           dropout_41[0][0]                 \n",
            "                                                                 conv1d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 500, 100)     400         add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 500, 100)     0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_37 (AveragePo (None, 62, 100)      0           activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_37 (Flatten)            (None, 6200)         0           average_pooling1d_37[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_37 (Dense)                (None, 30)           186030      flatten_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 30)           0           dense_37[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 200,062\n",
            "Trainable params: 199,606\n",
            "Non-trainable params: 456\n",
            "__________________________________________________________________________________________________\n",
            "594/594 [==============================] - 9s 15ms/step - loss: 0.5704 - accuracy: 0.8370\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.2738 - accuracy: 0.9233\n",
            "(pretraining) Testing accuracy from within X_reference.npy and y_reference.npy: 0.9233333468437195\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 3.1488 - accuracy: 0.5320\n",
            "Testing loss, accuracy after pretraining from X_test and y_test: 3.1487796306610107 0.5320000052452087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3s9kNMu3TtI",
        "colab_type": "text"
      },
      "source": [
        "Finetuning Hyperparameters and Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CruboOEw1SKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c010a0f-5a7a-4c83-a036-5601a194d020"
      },
      "source": [
        "#finetune hyperparameters\n",
        "ft_batch_size = 10\n",
        "ft_epochs = 8\n",
        "ft_learningRate = 0.0001\n",
        "\n",
        "\n",
        "finetuned_model = ResNet.finetune(save_directory=save_directory, features=X_fine, labels=y_fine, epochs=ft_epochs, learningRate=ft_learningRate, batch_size=ft_batch_size)\n",
        "\n",
        "loss, acc = finetuned_model.evaluate(X_test, y_test, batch_size=ft_batch_size, verbose=verbose)\n",
        "print(\"Pretrained accuracy: \", pre_acc)\n",
        "print(\"Fintuned accuracy: \", acc)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_38 (InputLayer)           [(None, 1000, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_115 (Conv1D)             (None, 500, 64)      320         input_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 500, 64)      256         conv1d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 500, 64)      0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 500, 64)      256         activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 500, 64)      0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_116 (Conv1D)             (None, 500, 100)     6400        activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 500, 100)     0           conv1d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_117 (Conv1D)             (None, 500, 100)     6400        activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 500, 100)     0           dropout_41[0][0]                 \n",
            "                                                                 conv1d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 500, 100)     400         add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 500, 100)     0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_37 (AveragePo (None, 62, 100)      0           activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_37 (Flatten)            (None, 6200)         0           average_pooling1d_37[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_37 (Dense)                (None, 30)           186030      flatten_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 30)           0           dense_37[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 200,062\n",
            "Trainable params: 199,606\n",
            "Non-trainable params: 456\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/8\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 1.3858 - accuracy: 0.6674\n",
            "Epoch 2/8\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 0.7702 - accuracy: 0.7747\n",
            "Epoch 3/8\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 0.5967 - accuracy: 0.8214\n",
            "Epoch 4/8\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 0.4939 - accuracy: 0.8540\n",
            "Epoch 5/8\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 0.4254 - accuracy: 0.8758\n",
            "Epoch 6/8\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 0.3724 - accuracy: 0.8881\n",
            "Epoch 7/8\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 0.3397 - accuracy: 0.9060\n",
            "Epoch 8/8\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 0.3003 - accuracy: 0.9147\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8800\n",
            "(finetuning) Testing accuracy from within X_fine and y_fine:  0.8799999952316284\n",
            "300/300 [==============================] - 1s 2ms/step - loss: 0.5905 - accuracy: 0.8343\n",
            "Pretrained accuracy:  0.5320000052452087\n",
            "Fintuned accuracy:  0.8343333601951599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lieMcj-3ZPg",
        "colab_type": "text"
      },
      "source": [
        "Todo:\n",
        "*   Create hyperparameter tuning framework\n",
        "*   Separate/clean up mounting google drive and loading files\n",
        "*   Add confusion matrix\n",
        "*   Comment code\n",
        "*   Add clinical tuning method \n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}